{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoccerNet Object Tracking\n",
    "#### 02456 Deep learning 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import re\n",
    "import seaborn as sn\n",
    "from IPython.display import Video, Image\n",
    "from glob import glob\n",
    "from io import TextIOWrapper\n",
    "import collections\n",
    "import zipfile\n",
    "import csv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SoccerNet\n",
    "# from SoccerNet.Downloader import SoccerNetDownloader\n",
    "# mySoccerNetDownloader=SoccerNetDownloader(LocalDirectory=\"path/to/SoccerNet\")\n",
    "# mySoccerNetDownloader.downloadDataTask(task=\"tracking\", split=[\"train\", \"test\", \"challenge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to visualize boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_np_array_from_tar_object(tar_extractfl):\n",
    "     '''converts a buffer from a tar file in np.array'''\n",
    "     return np.asarray(bytearray(tar_extractfl.read()), dtype=np.uint8)\n",
    "\n",
    "def collect(fn):\n",
    "    archive = zipfile.ZipFile(fn, 'r')\n",
    "    annotated_images = []\n",
    "\n",
    "    annotation_files = []\n",
    "    for f in archive.namelist():\n",
    "        if \"det/det.txt\" in f:\n",
    "            annotation_files.append(f)\n",
    "\n",
    "    image_annotations = collections.defaultdict(list)\n",
    "\n",
    "    for af in annotation_files:\n",
    "        st, sample,_,__ = af.split(\"/\")\n",
    "        imgpath = \"%s/%s/img1/%06d.jpg\"\n",
    "        for row in csv.reader(TextIOWrapper(archive.open(af), 'utf-8') ):\n",
    "            frame, _, x, y, w, h = [int(x) for x in row[:6]]\n",
    "            ifn = imgpath%(st,sample, frame)\n",
    "            image_annotations[ifn].append((x,y,w,h))\n",
    "\n",
    "    for k in image_annotations.keys():\n",
    "        img = cv2.imdecode(get_np_array_from_tar_object(archive.open(k)), 1 )\n",
    "        for box in image_annotations[k]:\n",
    "            x,y,w,h = box\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0), 2)\n",
    "\n",
    "        img = cv2.resize(img, (0,0), fx=0.75, fy=0.75)\n",
    "        cv2.imshow('image',img)\n",
    "        cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize\n",
    "# train = collect(\"path/to/SoccerNet/tracking/train.zip\")\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test YOLOv7 with SoccerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_base = 'yolov7'\n",
    "sn_track_base = 'path/to/SoccerNet/tracking'\n",
    "\n",
    "# ４ types of labels are used.\n",
    "labels = ['ball', 'player', 'referee', 'goalkeepers']\n",
    "label_dict = {'ball': 0, 'player': 1, 'referee': 2, 'goalkeeper': 3, 'goalkeepers': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of the 57 half , 50 are used for training and 7 for validation.\n",
    "#trn_dirs = sorted(glob(f'{sn_track_base}/train/SNMOT*'))\n",
    "#tst_dirs = sorted(glob(f'{sn_track_base}/test/SNMOT*'))\n",
    "trn_dirs = [\"C:/Users/Administrator/Desktop/SNMOT-060\"]\n",
    "tst_dirs = [\"C:/Users/Administrator/Desktop/SNMOT-116\"]\n",
    "\n",
    "split_dirs = {\n",
    "    'train':trn_dirs,\n",
    "    'valid':tst_dirs\n",
    "}\n",
    "\n",
    "# ４ types of labels are used.\n",
    "labels = ['ball', 'player', 'referee', 'goalkeepers']\n",
    "label_dict = {'ball': 0, 'player': 1, 'referee': 2, 'goalkeeper': 3, 'goalkeepers': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) image file path\n",
    "yolo_train_img_dir = f'{yolo_base}/images/train'\n",
    "yolo_valid_img_dir = f'{yolo_base}/images/valid'\n",
    "\n",
    "#(2) label file path\n",
    "yolo_train_label_dir = f'{yolo_base}/labels/train'\n",
    "yolo_valid_label_dir = f'{yolo_base}/labels/valid'\n",
    "\n",
    "#(3) config file path\n",
    "yaml_file = f'{yolo_base}/data.yaml'\n",
    "\n",
    "#!rm -rf /home/tito/kaggle/dfl-bundesliga-data-shootout/work/yolov5\n",
    "os.makedirs(yolo_train_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_valid_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_train_label_dir, exist_ok=True)\n",
    "os.makedirs(yolo_valid_label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this_dir: C:/Users/Administrator/Desktop/SNMOT-060\n",
      "this_dir: C:/Users/Administrator/Desktop/SNMOT-116\n"
     ]
    }
   ],
   "source": [
    "# convert from x,y,w,h to yolo format\n",
    "def get_yolo_format_bbox(img_w, img_h, box):\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "    xc = box[0] + int(np.round(w/2))\n",
    "    yc = box[1] + int(np.round(h/2))\n",
    "    box = [xc/img_w, yc/img_h, w/img_w, h/img_h]\n",
    "    box = [f\"{i:.4g}\" for i in box]\n",
    "    return box\n",
    "    \n",
    "# get SoccerNet label info \n",
    "def get_info(info):\n",
    "    results = []\n",
    "    for line in open(info):\n",
    "        m = re.match('trackletID_(\\d+)= (\\S*).*', line.replace(';', ' '))\n",
    "        if m:\n",
    "            if m.group(2) not in label_dict:\n",
    "                #print('bad label:', m.group(2))\n",
    "                continue \n",
    "            results.append([m.group(1), m.group(2)])\n",
    "    return pd.DataFrame(results, columns=['id','lbl']).set_index('id').to_dict()['lbl']\n",
    "\n",
    "# make image simlink and label files\n",
    "for split in split_dirs:\n",
    "    if split == 'train':\n",
    "        yolo_img_dir = yolo_train_img_dir\n",
    "        yolo_label_dir = yolo_train_label_dir\n",
    "    else:\n",
    "        yolo_img_dir = yolo_valid_img_dir\n",
    "        yolo_label_dir = yolo_valid_label_dir\n",
    "        \n",
    "    for this_dir in split_dirs[split]:\n",
    "        print('this_dir:',this_dir)\n",
    "        video = this_dir.split('/')[-1]\n",
    "        info = this_dir + '/gameinfo.ini'\n",
    "        det = this_dir + '/gt/gt.txt'\n",
    "        info_dict = get_info(info)\n",
    "        det_df = pd.read_csv(det, names=['frame','player','x','y','w','h','f1','f2','f3','f4'], usecols=['frame','player','x','y','w','h'])\n",
    "        det_df['label'] = det_df.player.astype(str).map(info_dict)\n",
    "        det_df['label_id'] = det_df['label'].map(label_dict)\n",
    "        # check\n",
    "        ng_list = list(det_df[det_df.label_id.isnull()].label.unique())\n",
    "        if len(ng_list)>0:\n",
    "            #print('ng_list:',ng_list, det_df.dropna().shape, det_df.shape)\n",
    "            det_df = det_df.dropna()\n",
    "        for grp, grp_df in det_df.groupby('frame'):\n",
    "            frame = f'{grp:06}'\n",
    "            img_file = f'{this_dir}/img1/{frame}.jpg'\n",
    "            dst_file = f'{yolo_img_dir}/{video}_{frame}.jpg'\n",
    "            if not os.path.exists(dst_file):\n",
    "                os.symlink(img_file, dst_file)\n",
    "                #print(img_file)\n",
    "            img = cv2.imread(dst_file)\n",
    "            height, width, _ = img.shape \n",
    "            bboxes = []\n",
    "            for arr in grp_df[['x', 'y', 'w', 'h', 'label_id']].values:\n",
    "                box = get_yolo_format_bbox(width, height, arr[:4])\n",
    "                bboxes.append([arr[4]]+box)\n",
    "            file_name = f'{yolo_label_dir}/{video}_{frame}.txt'\n",
    "            with open(file_name, 'w') as f:\n",
    "                for i, bbox in enumerate(bboxes):\n",
    "                    bbox = [str(i) for i in bbox]\n",
    "                    str_bbox = ' '.join(bbox)\n",
    "                    f.write(str_bbox)\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump config file\n",
    "data_yaml = dict(\n",
    "    train = yolo_train_img_dir,\n",
    "    val = yolo_valid_img_dir,\n",
    "    nc = 4,\n",
    "    names = labels\n",
    ")\n",
    "\n",
    "with open(yaml_file, 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "\n",
      "WARNING: Dataset not found, nonexistent paths: ['yolov7\\\\images\\\\valid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  2022-11-14 torch 1.11.0+cpu CPU\n",
      "\n",
      "Namespace(weights='C:/Users/Administrator/Desktop/SoccerNet/yolov7/yolov7-w6_training.pt', cfg='cfg/training/yolov7-w6.yaml', data='data.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=10, batch_size=4, img_size=[1280, 1280], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=2, project='runs/train', entity=None, name='yolov7-w6-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs\\\\train\\\\yolov7-w6-custom3', total_batch_size=4)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-28 15:22:29.677437: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-11-28 15:22:29.677460: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1         0  models.common.ReOrg                     []                            \n",
      "  1                -1  1      7040  models.common.Conv                      [12, 64, 3, 1]                \n",
      "  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  3                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  4                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 11                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      " 12                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 13                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 16                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 17                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 18  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 20                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 22                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 23                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 24                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 27  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 29                -1  1   3540480  models.common.Conv                      [512, 768, 3, 2]              \n",
      " 30                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 31                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 32                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
      " 33                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
      " 34                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
      " 35                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1181184  models.common.Conv                      [1536, 768, 1, 1]             \n",
      " 38                -1  1   7079936  models.common.Conv                      [768, 1024, 3, 2]             \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
      " 42                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
      " 43                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
      " 44                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
      " 45  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 46                -1  1   2099200  models.common.Conv                      [2048, 1024, 1, 1]            \n",
      " 47                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 48                -1  1    197376  models.common.Conv                      [512, 384, 1, 1]              \n",
      " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 50                37  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 52                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 53                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 54                -1  1    663936  models.common.Conv                      [384, 192, 3, 1]              \n",
      " 55                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
      " 56                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
      " 57                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
      " 58[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 59                -1  1    590592  models.common.Conv                      [1536, 384, 1, 1]             \n",
      " 60                -1  1     98816  models.common.Conv                      [384, 256, 1, 1]              \n",
      " 61                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 62                28  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 63          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 64                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 65                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 66                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 67                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 68                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 69                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 70[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 71                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 72                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 73                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 74                19  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 75          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 76                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 77                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 78                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 79                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 80                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 81                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 82[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 83                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 84                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      " 85          [-1, 71]  1         0  models.common.Concat                    [1]                           \n",
      " 86                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 87                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 88                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 89                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 90                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 91                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 92[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 93                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 94                -1  1    885504  models.common.Conv                      [256, 384, 3, 2]              \n",
      " 95          [-1, 59]  1         0  models.common.Concat                    [1]                           \n",
      " 96                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 97                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 98                -1  1    663936  models.common.Conv                      [384, 192, 3, 1]              \n",
      " 99                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
      "100                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
      "101                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
      "102[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "103                -1  1    590592  models.common.Conv                      [1536, 384, 1, 1]             \n",
      "104                -1  1   1770496  models.common.Conv                      [384, 512, 3, 2]              \n",
      "105          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
      "106                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      "107                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      "108                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      "109                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "110                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "111                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "112[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "113                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "114                83  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
      "115                93  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
      "116               103  1   2655744  models.common.Conv                      [384, 768, 3, 1]              \n",
      "117               113  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      "118                83  1    369280  models.common.Conv                      [128, 320, 3, 1]              \n",
      "119                71  1   1475840  models.common.Conv                      [256, 640, 3, 1]              \n",
      "120                59  1   3319680  models.common.Conv                      [384, 960, 3, 1]              \n",
      "121                47  1   5900800  models.common.Conv                      [512, 1280, 3, 1]             \n",
      "122[114, 115, 116, 117, 118, 119, 120, 121]  1    158404  models.yolo.IAuxDetect                  [4, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [256, 512, 768, 1024, 320, 640, 960, 1280]]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 477 layers, 80996420 parameters, 80996420 gradients, 102.5 GFLOPS\n",
      "\n",
      "Transferred 646/668 items from C:/Users/Administrator/Desktop/SoccerNet/yolov7/yolov7-w6_training.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrator\\Desktop\\Deep Learning VEO\\SoccerNetDeepLearning2022\\yolov7_Notebook\\yolov7\\train.py\", line 616, in <module>\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"C:\\Users\\Administrator\\Desktop\\Deep Learning VEO\\SoccerNetDeepLearning2022\\yolov7_Notebook\\yolov7\\train.py\", line 97, in train\n",
      "    check_dataset(data_dict)  # check\n",
      "  File \"C:\\Users\\Administrator\\Desktop\\Deep Learning VEO\\SoccerNetDeepLearning2022\\yolov7_Notebook\\yolov7\\utils\\general.py\", line 173, in check_dataset\n",
      "    raise Exception('Dataset not found.')\n",
      "Exception: Dataset not found.\n"
     ]
    }
   ],
   "source": [
    "# train!\n",
    "weight_file = 'C:/Users/Administrator/Desktop/SoccerNet/yolov7/yolov7-w6_training.pt'\n",
    "!cd $yolo_base && python train_aux.py \\\n",
    "    --workers 2 \\\n",
    "    --batch-size 4 \\\n",
    "    --data data.yaml \\\n",
    "    --img 1280 \\\n",
    "    --epochs 10 \\\n",
    "    --cfg cfg/training/yolov7-w6.yaml \\\n",
    "    --weights $weight_file \\\n",
    "    --name yolov7-w6-custom \\\n",
    "    --hyp data/hyp.scratch.custom.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['C:/Users/Administrator/Desktop/SoccerNet/yolov7/yolov7-w6_training.pt'], source='test_imgs', img_size=1280, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='dfl', name='exp', exist_ok=False, no_trace=False)\n",
      "Fusing layers... \n",
      "IAuxDetect.fuse\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "16 persons, Done. (2329.7ms) Inference, (15.6ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000001.jpg\n",
      "16 persons, Done. (2200.8ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000002.jpg\n",
      "17 persons, Done. (2218.3ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000003.jpg\n",
      "17 persons, Done. (2219.0ms) Inference, (15.6ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000004.jpg\n",
      "17 persons, Done. (2218.2ms) Inference, (4.1ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000005.jpg\n",
      "17 persons, Done. (2465.8ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000006.jpg\n",
      "17 persons, Done. (2489.5ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000007.jpg\n",
      "17 persons, Done. (2682.7ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000008.jpg\n",
      "17 persons, Done. (2653.7ms) Inference, (5.8ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000009.jpg\n",
      "17 persons, Done. (2734.7ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp\\000010.jpg\n",
      "Results saved to dfl\\exp\n",
      "10 labels saved to dfl\\exp\\labels\n",
      "Done. (25.453s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  2022-11-14 torch 1.11.0+cpu CPU\n",
      "\n",
      "Model Summary: 370 layers, 82277300 parameters, 0 gradients\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# predict!\n",
    "check_images = f'test_imgs'\n",
    "#weight_file = 'yolov7-w6_training.pt'\n",
    "# weight_file = 'yolov7.pt'\n",
    "!cd $yolo_base && python detect.py \\\n",
    "    --weights $weight_file \\\n",
    "    --source  $check_images \\\n",
    "    --img-size 1280 \\\n",
    "    --project dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some results. \n",
    "display(Image(f'{yolo_base}/dfl/exp9/000200.jpg'))\n",
    "display(Image(f'{yolo_base}/dfl/exp9/000400.jpg'))\n",
    "display(Image(f'{yolo_base}/dfl/exp9/000600.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
