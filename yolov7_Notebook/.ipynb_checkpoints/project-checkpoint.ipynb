{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoccerNet Object Tracking\n",
    "#### 02456 Deep learning 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import re\n",
    "import seaborn as sn\n",
    "from IPython.display import Video, Image\n",
    "from glob import glob\n",
    "from io import TextIOWrapper\n",
    "import collections\n",
    "import zipfile\n",
    "import csv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SoccerNet\n",
    "# from SoccerNet.Downloader import SoccerNetDownloader\n",
    "# mySoccerNetDownloader=SoccerNetDownloader(LocalDirectory=\"path/to/SoccerNet\")\n",
    "# mySoccerNetDownloader.downloadDataTask(task=\"tracking\", split=[\"train\", \"test\", \"challenge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to visualize boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_np_array_from_tar_object(tar_extractfl):\n",
    "     '''converts a buffer from a tar file in np.array'''\n",
    "     return np.asarray(bytearray(tar_extractfl.read()), dtype=np.uint8)\n",
    "\n",
    "def collect(fn):\n",
    "    archive = zipfile.ZipFile(fn, 'r')\n",
    "    annotated_images = []\n",
    "\n",
    "    annotation_files = []\n",
    "    for f in archive.namelist():\n",
    "        if \"det/det.txt\" in f:\n",
    "            annotation_files.append(f)\n",
    "\n",
    "    image_annotations = collections.defaultdict(list)\n",
    "\n",
    "    for af in annotation_files:\n",
    "        st, sample,_,__ = af.split(\"/\")\n",
    "        imgpath = \"%s/%s/img1/%06d.jpg\"\n",
    "        for row in csv.reader(TextIOWrapper(archive.open(af), 'utf-8') ):\n",
    "            frame, _, x, y, w, h = [int(x) for x in row[:6]]\n",
    "            ifn = imgpath%(st,sample, frame)\n",
    "            image_annotations[ifn].append((x,y,w,h))\n",
    "\n",
    "    for k in image_annotations.keys():\n",
    "        img = cv2.imdecode(get_np_array_from_tar_object(archive.open(k)), 1 )\n",
    "        for box in image_annotations[k]:\n",
    "            x,y,w,h = box\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0), 2)\n",
    "\n",
    "        img = cv2.resize(img, (0,0), fx=0.75, fy=0.75)\n",
    "        cv2.imshow('image',img)\n",
    "        cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize\n",
    "# train = collect(\"path/to/SoccerNet/tracking/train.zip\")\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test YOLOv7 with SoccerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_base = 'yolov7'\n",
    "sn_track_base = 'path/to/SoccerNet/tracking'\n",
    "\n",
    "# ï¼” types of labels are used.\n",
    "labels = ['ball', 'player', 'referee', 'goalkeepers']\n",
    "label_dict = {'ball': 0, 'player': 1, 'referee': 2, 'goalkeeper': 3, 'goalkeepers': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['yolov7.pt'], source='test_imgs', img_size=1280, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='dfl', name='exp', exist_ok=False, no_trace=False)\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  2022-11-14 torch 1.11.0+cpu CPU\n",
      "\n",
      "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "22 persons, Done. (2355.3ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000001.jpg\n",
      "21 persons, Done. (2194.5ms) Inference, (15.6ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000002.jpg\n",
      "21 persons, Done. (2188.0ms) Inference, (15.6ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000003.jpg\n",
      "21 persons, Done. (2275.3ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000004.jpg\n",
      "20 persons, Done. (2813.6ms) Inference, (15.6ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000005.jpg\n",
      "19 persons, Done. (2573.0ms) Inference, (15.6ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000006.jpg\n",
      "20 persons, Done. (2754.1ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000007.jpg\n",
      "20 persons, Done. (2766.8ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000008.jpg\n",
      "19 persons, Done. (2641.4ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000009.jpg\n",
      "19 persons, Done. (2845.6ms) Inference, (0.0ms) NMS\n",
      " The image with the result is saved in: dfl\\exp2\\000010.jpg\n",
      "Results saved to dfl\\exp2\n",
      "10 labels saved to dfl\\exp2\\labels\n",
      "Done. (26.555s)\n"
     ]
    }
   ],
   "source": [
    "# predict!\n",
    "check_images = f'test_imgs'\n",
    "weight_file = 'yolov7-w6_training.pt'\n",
    "# weight_file = 'yolov7.pt'\n",
    "!cd $yolo_base && python detect.py \\\n",
    "    --weights $weight_file \\\n",
    "    --source  $check_images \\\n",
    "    --img-size 1280 \\\n",
    "    --project dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some results. \n",
    "display(Image(f'{yolo_base}/dfl/exp9/000200.jpg'))\n",
    "display(Image(f'{yolo_base}/dfl/exp9/000400.jpg'))\n",
    "display(Image(f'{yolo_base}/dfl/exp9/000600.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
